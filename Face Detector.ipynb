{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_path:  images_training\\0\\ajith1.jpg\n",
      "ids:  0\n",
      "labels_for_training\n",
      "img_path:  images_training\\0\\ajith10.jpg\n",
      "ids:  0\n",
      "img_path:  images_training\\0\\ajith2.jpg\n",
      "ids:  0\n",
      "labels_for_training\n",
      "img_path:  images_training\\0\\ajith3.jpg\n",
      "ids:  0\n",
      "labels_for_training\n",
      "img_path:  images_training\\0\\ajith5.jpg\n",
      "ids:  0\n",
      "img_path:  images_training\\0\\ajith6.jpg\n",
      "ids:  0\n",
      "labels_for_training\n",
      "img_path:  images_training\\0\\ajith7.jpg\n",
      "ids:  0\n",
      "img_path:  images_training\\0\\ajith9.jpg\n",
      "ids:  0\n",
      "img_path:  images_training\\1\\surya1.jpg\n",
      "ids:  1\n",
      "labels_for_training\n",
      "img_path:  images_training\\1\\surya2.jpg\n",
      "ids:  1\n",
      "labels_for_training\n",
      "img_path:  images_training\\1\\surya4.jpg\n",
      "ids:  1\n",
      "img_path:  images_training\\1\\surya6.jpg\n",
      "ids:  1\n",
      "img_path:  images_training\\1\\surya7.jpg\n",
      "ids:  1\n",
      "labels_for_training\n",
      "img_path:  images_training\\1\\surya8.jpg\n",
      "ids:  1\n",
      "img_path:  images_training\\1\\surya9.jpg\n",
      "ids:  1\n",
      "labels_for_training\n",
      "(8, 250000)\n",
      "[0, 0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import train as tr\n",
    "\n",
    "def draw_rectangle(test_img,face):\n",
    "    (x,y,w,h)=face\n",
    "    cv2.rectangle(test_img,(x,y),(x+w,y+h),(0,255,0),thickness=2)\n",
    "\n",
    "def put_text(test_img,text,x,y):\n",
    "    cv2.putText(test_img,text,(x,y),cv2.FONT_HERSHEY_DUPLEX,1,(255,0,0),1)\n",
    "\n",
    "def detect_test_face(faces_detected):\n",
    "    for face in faces_detected:\n",
    "        (x,y,w,h)=face\n",
    "        roi_gray=gray_img[y:y+h,x:x+h]\n",
    "        roi_gray=cv2.resize(roi_gray,(500,500))\n",
    "        temp_ndarray=np.reshape(roi_gray,(1,(roi_gray.shape[0]*roi_gray.shape[0])))\n",
    "        NN_predicted=test_give_image(temp_ndarray)\n",
    "        draw_rectangle(test_img,face)\n",
    "        predicted_name=name[NN_predicted]\n",
    "        print(NN_predicted)\n",
    "        put_text(test_img,predicted_name,x,y)\n",
    "        print(predicted_name)\n",
    "\n",
    "name={0:\"Ajith\",1:\"Suriya\"}\n",
    "# Step1:\n",
    "directory='images_training'\n",
    "faces,faceID,x_train=tr.labels_for_training(directory)\n",
    "print(faceID)\n",
    "# training the data for the first time and save it so that it will usefull for next iterations\n",
    "#face_recognizer_model=train_classifier(faces,faceID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(faceID)\n",
    "X=x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(LogisticRegressionModel,self).__init__()\n",
    "        self.linear = nn.Linear(input_dim,output_dim)\n",
    "        # Logistic function is implemented at loss function or inbulit so will implement there\n",
    "    def forward(self,x):\n",
    "        out=self.linear(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "input_dim=500*500\n",
    "output_dim=2\n",
    "# Create a logistic regression model\n",
    "model= LogisticRegressionModel(input_dim,output_dim)\n",
    "error= nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate=0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "num_epochs=300\n",
    "\n",
    "# Tensor Dataset and Tensor data loader\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch.from_numpy(X).float(),torch.from_numpy(y).long())\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = False)\n",
    "\n",
    "\n",
    "# Traning the Model\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 500*500))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "        \n",
    "def test_give_image(temp_ndarray):\n",
    "    tensorX=torch.from_numpy(temp_ndarray).float()\n",
    "    test = Variable(tensorX.view(-1, 500*500))\n",
    "    outputs = model(test)\n",
    "    # Get predictions from the maximum value\n",
    "    predicted = torch.max(outputs.data, 1)[1]\n",
    "    return int(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces_detected: [[ 15  70 129 129]]\n",
      "0\n",
      "Ajith\n"
     ]
    }
   ],
   "source": [
    "test_img=cv2.imread('images_test//ajith4.jpg')#test_img path\n",
    "faces_detected,gray_img=tr.faceDetection(test_img)\n",
    "print(\"faces_detected:\",faces_detected)\n",
    "\n",
    "# step 2 pass the detected faces in case of group photos\n",
    "detect_test_face(faces_detected)\n",
    "resized_img=cv2.resize(test_img,(500,500))\n",
    "cv2.imshow(\"face dtecetion tutorial\",resized_img)\n",
    "cv2.waitKey(0)#Waits indefinitely until a key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
